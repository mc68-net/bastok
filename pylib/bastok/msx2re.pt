from    bastok.msx2re  import *
from    bastok.msxchars  import UTCharset, CHARMAP
from    re  import escape
import  pytest

#   When we don't need to have distinguishable Unicode and native
#   codepoints, this is easier to use.
ja_charmap = CHARMAP['ja']

####################################################################

@pytest.mark.parametrize('s, b', [
    ('\uF000', b'\x01\x40'),
    ('\uF01F', b'\x01\x5F'),
    ('\uF020', b'\x20'),
    ('\uF080', b'\x80'),
    ('\uF0FF', b'\xFF'),
])
def test_char_good(s, b):
    p = PState(s, UTCharset())
    char(p)
    assert b == p.output()

def test_char_encodingerror():
    p = PState('\uF07F', UTCharset())
    with pytest.raises(EncodingError) as ex:
        char(p)
    assert ex.match('0x7F')

def test_char_eoi():
    p = PState('', None)
    with pytest.raises(p.ParseError) as ex:
        char(p)
    assert ex.match('unexpected end of input')
    assert None is char(p, err=None)

def test_chars():
    p = PState('bcd', UTCharset(1))
    chars(p)
    assert b'abc' == p.output()

@pytest.mark.parametrize('s, b, r', [
    ('x'    , None  , 'x'),
    ('  x'  , b'  ' , 'x'),
    (''     , None  , ''),
    ('  '   , b'  ' , ''),
])
def test_spaces(s, b, r):
    p = PState(s, ja_charmap)
    spaces(p);        assert (b, r) == (p.output(), p.remain())
    p = PState(s, ja_charmap)
    spaces(p, False); assert (None, r) == (p.output(), p.remain())

def test_spaces_default():
    p = PState('  x', ja_charmap)
    spaces(p); assert (b'  ', 'x') == (p.output(), p.remain())

@pytest.mark.parametrize('s, b', [
    ('""',          b'""'),
    ('""x',         b'""'),
    ('"',           b'"'),
    ('"xyz',        b'"xyz'),
    ('"Aaあ年".',   b'"Aa\x91\x01\x48"'),
    ('"Aaあ年',     b'"Aa\x91\x01\x48'),
])
def test_string_literal_success(s, b):
    p = PState(s, ja_charmap)
    string_literal(p)
    assert b == p.output()

def test_string_literal_error():
    p = PState('a')
    with pytest.raises(p.ParseError) as ex:
        string_literal(p)
    assert ex.match("unexpected input: 'a'")
    assert None is string_literal(p, err=None)


####################################################################


#   XXX what should we be doing about lower case in program text?
#   Maybe add an `insensitive` property to PState and have parse functions
#   use that to determine if they're "liberal" in what they accept, e.g.,
#   toktrans() will do a case-insensitive comparision on strings.

@pytest.mark.parametrize('lineno, tokens, line', [
    ( 10, b'\x8F SAVE',             '10 REM SAVE'),
    ( 10, b':\x8F\xE6 SAVE',        "10 ' SAVE"),
    ( 20, b'\x91: \x8Fark=:=',      '20 PRINT: REMark=:='),
    ( 30, b'A$\xEF"a"\xF1"\x91"',   '30 A$="a"+"あ"'),
    #   $0E is prefix for a 16-bit little-endian int.
    ( 40, b'\x89\x20\x0E\x2E\x16',  '40 GOTO 5678'), # 5678=$162E
    #  41 24 ef 22 61 22 f1 22 91 22
])
def test_tokline(lineno, tokens, line):
    assert (lineno, tokens) == tokline(ja_charmap, line)

@pytest.mark.parametrize('line, msg', [
    ('GOTO',                'line number at 0'),
    ('10 GOTO -1',          'line number after GOTO'),
])
def test_tokline_error(line, msg):
    with pytest.raises(PState.ParseError) as ex:
        tokline(ja_charmap, line)
    assert ex.match('expected ' + msg)

def test_tokenize():
    inlines = [ "10 REM",      "20 PRINT", ]
    tlines  = ( (10, b'\x8F'), (20, b'\x91') )
    assert tlines == tuple(tokenize(ja_charmap, inlines).lines())

def test_tokenize_duplicate_lines():
    pass # XXX
