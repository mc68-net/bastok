from    bastok.msx2re  import *
from    bastok.msxchars  import UTCharset, CHARMAP
from    re  import escape
import  pytest

#   When we don't need to have distinguishable Unicode and native
#   codepoints, this is easier to use.
ja_charmap = CHARMAP['ja']

####################################################################

@pytest.mark.parametrize('s, b', [
    ('\uF000', b'\x01\x40'),
    ('\uF01F', b'\x01\x5F'),
    ('\uF020', b'\x20'),
    ('\uF080', b'\x80'),
    ('\uF0FF', b'\xFF'),
])
def test_char_good(s, b):
    p = PState(s, UTCharset())
    char(p)
    assert b == p.output()

def test_char_encodingerror():
    p = PState('\uF07F', UTCharset())
    with pytest.raises(EncodingError) as ex:
        char(p)
    assert ex.match('0x7F')

def test_char_eoi():
    p = PState('', None)
    with pytest.raises(p.ParseError) as ex:
        char(p)
    assert ex.match('unexpected end of input')
    assert None is char(p, err=None)

def test_chars():
    p = PState('bcd', UTCharset(1))
    chars(p)
    assert b'abc' == p.output()

@pytest.mark.parametrize('s, b', [
    ('""',          b'""'),
    ('""x',         b'""'),
    ('"',           b'"'),
    ('"xyz',        b'"xyz'),
    ('"Aaあ年".',   b'"Aa\x91\x01\x48"'),
    ('"Aaあ年',     b'"Aa\x91\x01\x48'),
])
def test_string_literal_success(s, b):
    p = PState(s, ja_charmap)
    string_literal(p)
    assert b == p.output()

def test_string_literal_error():
    p = PState('a')
    with pytest.raises(p.ParseError) as ex:
        string_literal(p)
    assert ex.match("unexpected input: 'a'")
    assert None is string_literal(p, err=None)

####################################################################


#   XXX what should we be doing about lower case in program text?
#   Maybe add an `insensitive` property to PState and have parse functions
#   use that to determine if they're "liberal" in what they accept, e.g.,
#   toktrans() will do a case-insensitive comparision on strings.

@pytest.mark.parametrize('lineno, tokens, line', [
    ( 10, b'\x8F',                  '10 REM'),
    ( 20, b'\x91: \x8Fark=:=',      '20 PRINT: REMark=:='),
    ( 30, b'A$\xEF"a"\xF1"\x91"',   '30 A$="a"+"あ"'),
    #  41 24 ef 22 61 22 f1 22 91 22
])
def test_tokline(lineno, tokens, line):
    assert (lineno, tokens) == tokline(ja_charmap, line)

def test_tokenize():
    inlines = [ "10 REM",      "20 PRINT", ]
    tlines  = ( (10, b'\x8F'), (20, b'\x91') )
    assert tlines == tuple(tokenize(ja_charmap, inlines).lines())

def test_tokenize_duplicate_lines():
    pass # XXX
